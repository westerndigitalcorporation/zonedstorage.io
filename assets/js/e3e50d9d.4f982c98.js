"use strict";(self.webpackChunkzonedstorage_io=self.webpackChunkzonedstorage_io||[]).push([[8571],{9891:(e,n,t)=>{t.r(n),t.d(n,{No:()=>h,Yes:()=>c,assets:()=>a,contentTitle:()=>r,default:()=>u,frontMatter:()=>o,metadata:()=>l,toc:()=>d});var s=t(5893),i=t(1151);const o={id:"fs",title:"File Systems",sidebar_label:"File Systems"},r="File Systems",l={id:"linux/fs",title:"File Systems",description:"The dm-zoned device-mapper target makes it possible",source:"@site/docs/linux/fs.md",sourceDirName:"linux",slug:"/linux/fs",permalink:"/docs/linux/fs",draft:!1,unlisted:!1,tags:[],version:"current",frontMatter:{id:"fs",title:"File Systems",sidebar_label:"File Systems"},sidebar:"docs",previous:{title:"Device Mapper",permalink:"/docs/linux/dm"},next:{title:"Overview",permalink:"/docs/applications"}},a={},d=[{value:"zonefs",id:"zonefs",level:2},{value:"Overview",id:"overview",level:3},{value:"On-Disk Metadata",id:"on-disk-metadata",level:3},{value:"Zone Type Sub-Directories",id:"zone-type-sub-directories",level:3},{value:"Zone files",id:"zone-files",level:3},{value:"Conventional Zone Files",id:"conventional-zone-files",level:4},{value:"Sequential zone files",id:"sequential-zone-files",level:4},{value:"Format options",id:"format-options",level:3},{value:"IO error handling",id:"io-error-handling",level:3},{value:"Mount options",id:"mount-options",level:3},{value:"Zonefs User Space Tools",id:"zonefs-user-space-tools",level:3},{value:"Examples",id:"examples",level:3},{value:"f2fs",id:"f2fs",level:2},{value:"Zoned Block Device Support",id:"zoned-block-device-support",level:3},{value:"Zone Capacity Support",id:"zone-capacity-support",level:3},{value:"Limitations",id:"limitations",level:3},{value:"Usage Example with a Host Managed SMR HDD",id:"usage-example-with-a-host-managed-smr-hdd",level:3},{value:"Usage Example with a NVMe ZNS SSD",id:"usage-example-with-a-nvme-zns-ssd",level:3},{value:"Btrfs",id:"btrfs",level:2},{value:"Zoned Block Device Support",id:"zoned-block-device-support-1",level:3},{value:"Block Allocation Changes",id:"block-allocation-changes",level:3},{value:"I/O Management",id:"io-management",level:3},{value:"Zone Capacity Support",id:"zone-capacity-support-1",level:3},{value:"Limitations",id:"limitations-1",level:3},{value:"System Requirements",id:"system-requirements",level:3},{value:"Usage example with a Host Managed SMR HDD",id:"usage-example-with-a-host-managed-smr-hdd-1",level:3},{value:"XFS",id:"xfs",level:2},{value:"ext4",id:"ext4",level:2}];function c(){const e={span:"span",...(0,i.a)()};return(0,s.jsx)(e.span,{style:{color:"#00ff00"},children:"yes"})}function h(){const e={span:"span",...(0,i.a)()};return(0,s.jsx)(e.span,{style:{color:"#ff0000"},children:"no"})}function f(e){const n={a:"a",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",h4:"h4",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,i.a)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.h1,{id:"file-systems",children:"File Systems"}),"\n",(0,s.jsxs)(n.p,{children:["The ",(0,s.jsx)(n.a,{href:"/docs/linux/dm#dm-zoned",children:(0,s.jsx)(n.em,{children:"dm-zoned"})})," device-mapper target makes it possible\nto use any file system with host-managed zoned block devices. It does this by\nhiding the device's sequential write constraints. This solution is simple and\nmakes it possible to use file systems, but its potentially high overhead during\nthe block-based zone-reclamation process means that is not the maximally\nefficient solution."]}),"\n",(0,s.jsxs)(n.p,{children:["File systems whose implementations directly support zoned block devices have\nmore efficient zone-reclamation processing. This is because file systems that\ndirectly support zoned block devices have metadata and file abstractions that\nprovide more information about the usage and validity of storage blocks than\ndo file systems that take the ",(0,s.jsx)(n.em,{children:"dm-zoned"}),"-block-based approach."]}),"\n",(0,s.jsxs)(n.p,{children:["Some file systems are designed in such a way that they work well with the\nsequential write constraint of host-managed zoned block devices. This is the\ncase for log-structured file systems such as ",(0,s.jsx)(n.em,{children:"f2fs"})," and copy-on-write (CoW)\nfile systems such as ",(0,s.jsx)(n.em,{children:"Btrfs"}),"."]}),"\n",(0,s.jsx)(n.h2,{id:"zonefs",children:"zonefs"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.em,{children:"zonefs"})," is a very simple file system that exposes each of the zones of a zoned\nblock device as a file. ",(0,s.jsx)(n.em,{children:"zonefs"})," has been included with the upstream Linux\nkernel since version 5.6.0."]}),"\n",(0,s.jsx)(n.h3,{id:"overview",children:"Overview"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.em,{children:"zonefs"})," does not hide from the user the sequential write constraints of zoned\nblock devices. In this, it is unlike a regular POSIX-compliant file system\nwith native zoned-block device support (e.g. ",(0,s.jsx)(n.a,{href:"/docs/linux/fs#f2fs",children:(0,s.jsx)(n.em,{children:"f2fs"})}),').\nFiles that represent sequential write zones on the device must be written\nsequentially, starting from the end of the file (these are "append only"\nwrites).']}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.em,{children:"zonefs"})," is therefore more similar to a raw-block-device-access interface than\nit is to a full-featured POSIX file system. The goal of ",(0,s.jsx)(n.em,{children:"zonefs"}),' is to\nsimplify the implementation of zoned block device support in applications, and\nit aims to do this by replacing raw block device file accesses with the richer\nregular-file API (which avoids relying on the possibly more obscure and\ndeveloper-unfriendly direct block device file ioctls). One example of this\napproach is the implementation of LSM (log-structured merge) tree structures\n(such as used in RocksDB and LevelDB) on zoned block devices: SSTables are\nstored in a zone file in a way that is similar to the way a regular file\nsystem works rather than as a range of sectors of the entire disk. The\nintroduction of the higher-level construct "one file is one zone" can reduce\nthe number of changes needed in the application, and also introduces support\nfor different application programming languages.']}),"\n",(0,s.jsx)(n.p,{children:"The files that represent zones are grouped by zone type, and those zone types\nthemselves are represented by sub-directories. This file structure is built\nentirely using zone information that is provided by the device and therefore\ndoes not require any complex on-disk metadata structure."}),"\n",(0,s.jsx)(n.h3,{id:"on-disk-metadata",children:"On-Disk Metadata"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.em,{children:"zonefs"})," on-disk metadata is composed only of an immutable super block which\npersistently stores a magic number and optional feature flags and values. On\nmount, ",(0,s.jsx)(n.em,{children:"zonefs"})," uses the block layer API function ",(0,s.jsx)(n.code,{children:"blkdev_report_zones()"})," to\nobtain the device zone configuration and populates the mount point with a\nstatic file tree that is based solely on this information. File sizes come\nfrom the device zone type and the write-pointer position, both of which are\nmanaged by the device itself. ",(0,s.jsx)(n.em,{children:"zonefs"})," operates only based on information\nfrom the device. ",(0,s.jsx)(n.em,{children:"zonefs"})," does not have any metadata of its own."]}),"\n",(0,s.jsxs)(n.p,{children:["The super block is always written on disk at sector 0. The first zone of the\ndevice that stores the super block is never exposed as a zone file by\n",(0,s.jsx)(n.em,{children:"zonefs"}),". If the zone that contains the super block is a sequential zone, the\n",(0,s.jsx)(n.code,{children:"mkzonefs"}),' format tool always "finishes" the zone (that is, it transitions the\nzone to a full state to make it read-only, preventing any data write).']}),"\n",(0,s.jsx)(n.h3,{id:"zone-type-sub-directories",children:"Zone Type Sub-Directories"}),"\n",(0,s.jsx)(n.p,{children:"Files that represent zones of the same type are grouped together under the same\nsub-directory, which is automatically created on mount."}),"\n",(0,s.jsxs)(n.p,{children:['For conventional zones, the sub-directory "cnv" is used. This directory is\ncreated only if the device has usable conventional zones. If the device has\nonly a single conventional zone at sector 0, the zone will not be exposed as a\nfile (because it will be used to store the ',(0,s.jsx)(n.em,{children:"zonefs"}),' super block). For such\ndevices, the "cnv" sub-directory will not be created.']}),"\n",(0,s.jsx)(n.p,{children:'For sequential write zones, the sub-directory "seq" is used.'}),"\n",(0,s.jsxs)(n.p,{children:["These two directories are the only directories that exist in ",(0,s.jsx)(n.em,{children:"zonefs"}),'. Users\ncannot create other directories and can neither rename nor delete the "cnv"\nand "seq" sub-directories.']}),"\n",(0,s.jsxs)(n.p,{children:["The size of the directories indicates the number of files that exist under\nthe directory. This size is indicated by the ",(0,s.jsx)(n.code,{children:"st_size"})," field of ",(0,s.jsx)(n.code,{children:"struct stat"}),", which is obtained with the ",(0,s.jsx)(n.code,{children:"stat()"})," or ",(0,s.jsx)(n.code,{children:"fstat()"})," system calls."]}),"\n",(0,s.jsx)(n.h3,{id:"zone-files",children:"Zone files"}),"\n",(0,s.jsx)(n.p,{children:'Zone files are named using the number of the zone they represent within the\nset of zones of a particular type. Both the "cnv" and "seq" directories\ncontain files named "0", "1", "2", ... The file numbers also represent\nincreasing zone start sector on the device.'}),"\n",(0,s.jsxs)(n.p,{children:["No read- and write-operations to zone files are allowed beyond the file\nmaximum size (that is, beyond the zone size). Any access that exceeds the zone\nsize fails with the ",(0,s.jsx)(n.code,{children:"-EFBIG"})," error."]}),"\n",(0,s.jsx)(n.p,{children:"Creating, deleting, renaming and modifying any attribute of files is not\nallowed."}),"\n",(0,s.jsxs)(n.p,{children:["The number of blocks of a file as reported by ",(0,s.jsx)(n.code,{children:"stat()"})," and ",(0,s.jsx)(n.code,{children:"fstat()"})," indicates\nthe size of the file zone (in other words, the maximum file size)."]}),"\n",(0,s.jsx)(n.h4,{id:"conventional-zone-files",children:"Conventional Zone Files"}),"\n",(0,s.jsx)(n.p,{children:"The size of conventional zone files is fixed to the size of the zone that they\nrepresent. Conventional zone files cannot be truncated."}),"\n",(0,s.jsx)(n.p,{children:"These files can be randomly read and written using any type of I/O operation:\nbuffered I/Os, direct I/Os, memory mapped I/Os (mmap), etc. There are no I/O\nconstraints for these files beyond the file size limit mentioned above."}),"\n",(0,s.jsx)(n.h4,{id:"sequential-zone-files",children:"Sequential zone files"}),"\n",(0,s.jsx)(n.p,{children:'The size of sequential zone files that are grouped in the "seq" sub-directory\nrepresents the file\'s zone-write-pointer position relative to the zone start\nsector.'}),"\n",(0,s.jsxs)(n.p,{children:['Sequential zone files can be written only sequentially, starting from the file\nend (that is, write operations can be only "append writes"). ',(0,s.jsx)(n.code,{children:"zonefs"})," makes no\nattempt to accept random writes and will fail any write request that has a\nstart offset that does not correspond to the end of the file, or to the end of\nthe last write issued and still in-flight (for asynchronous I/O operations)."]}),"\n",(0,s.jsxs)(n.p,{children:["Because dirty page writeback by the page cache does not guarantee a sequential\nwrite pattern, ",(0,s.jsx)(n.em,{children:"zonefs"})," prevents buffered writes and writeable shared mappings\non sequential files. Only direct I/O writes are accepted for these files.\n",(0,s.jsx)(n.em,{children:"zonefs"})," relies on the sequential delivery of write I/O requests to the device\nimplemented by the block layer elevator (See\n",(0,s.jsx)(n.a,{href:"/docs/linux/sched",children:"Write Command Ordering"}),")."]}),"\n",(0,s.jsx)(n.p,{children:"There are no restrictions on the type of I/O used for read operations in\nsequential zone files. Buffered I/Os, direct I/Os and shared read mappings are\nall accepted."}),"\n",(0,s.jsx)(n.p,{children:"Truncating sequential zone files is allowed only down to 0, in which case, the\nzone is reset to rewind the file zone write pointer position to the start of\nthe zone, or up to the zone size, in which case the file's zone is transitioned\nto the FULL state (finish zone operation)."}),"\n",(0,s.jsx)(n.h3,{id:"format-options",children:"Format options"}),"\n",(0,s.jsxs)(n.p,{children:["Several optional features of ",(0,s.jsx)(n.em,{children:"zonefs"})," can be enabled at format time."]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:'Conventional zone aggregation: ranges of contiguous conventional zones can\nbe aggregated into a single larger file instead of the default "one file per\nzone".'}),"\n",(0,s.jsx)(n.li,{children:"File ownership: By default, the owner UID and GID of zone files is 0 (root)\nbut can be changed to any valid UID/GID."}),"\n",(0,s.jsx)(n.li,{children:"File access permissions: the default access permissions (640) can be changed."}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"io-error-handling",children:"IO error handling"}),"\n",(0,s.jsx)(n.p,{children:"Zoned block devices can fail I/O requests for reasons similar to the reasons\nthat regular block devices fail I/O requests, e.g. if there are bad sectors.\nBut the standards that govern the behavior of zoned block devices also define\nadditional conditions (in addition to these known I/O failure patterns) that\ncan result in I/O errors."}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"A zone may transition to the read-only condition:\nAlthough the data that is already written in the zone is still readable, the\nzone can no longer be written. No user action on the zone (zone management\ncommand or read/write access) can change the zone condition back to a\nnormal read/write state. While the reasons for the device to transition a\nzone to read-only state are not defined by the standards, a typical cause\nfor such transition would be a defective write head on an HDD (all zones\nunder this head are changed to read-only)."}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:'A zone may transition to the offline condition:\nAn offline zone can be neither read nor written. No user action can\ntransition an offline zone back to an operational "good state". Similar to\nzone read-only transitions, the reasons that a drive transitions a zone\nto the offline condition are undefined. A typical cause is (for example) a\ndefective read-write head on an HDD that causes all zones on the platter\nunder the broken head to be inaccessible.'}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:["Unaligned write errors:\nThese errors result from the device receiving a write request that has a\nstart sector that does not correspond to the write-pointer position of the\ntarget zone. Although ",(0,s.jsx)(n.em,{children:"zonefs"})," enforces sequential file write for\nsequential zones, unaligned write errors can still happen in the case of a\npartial failure of a very large direct I/O operation that is split into\nmultiple BIOs/requests or asynchronous I/O operations. If one of the write\nrequests within the set of sequential write requests that is issued to the\ndevice fails, all write requests that are queued after it will become\nunaligned and fail."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:["Delayed write errors:\nAs with regular block devices, if the device-side write cache is enabled,\nwrite errors can occur in ranges of previously-completed writes when the\ndevice write cache is flushed, e.g. on ",(0,s.jsx)(n.code,{children:"fsync()"}),".  As in cases of immediate\nunaligned write errors, delayed write errors can propagate through a stream\nof cached sequential data for a zone, which can cause all data after the\nsector that caused the error to be dropped."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:["All I/O errors detected by ",(0,s.jsx)(n.em,{children:"zonefs"})," are reported to the user with an error code\nreturned for the system call that triggered or detected the error. The recovery\nactions taken by ",(0,s.jsx)(n.em,{children:"zonefs"})," in response to I/O errors depend on the I/O type\n(read vs write) and on the reason for the error (bad sector, unaligned writes or\nzone condition change)."]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:["For read I/O errors, ",(0,s.jsx)(n.em,{children:"zonefs"})," takes recovery action action only if the file\nzone is still in good condition and there is no inconsistency between the\nfile inode size and its zone write pointer position. If a problem is\ndetected, I/O error recovery is executed (see below table)."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:["For write I/O errors, ",(0,s.jsx)(n.em,{children:"zonefs"})," I/O error recovery is always executed."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:['A zone condition change to "read-only" or "offline" also always triggers\n',(0,s.jsx)(n.em,{children:"zonefs"})," I/O error recovery."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.em,{children:"zonefs"})," minimal I/O error recovery can change a file's size and its file\naccess permissions."]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:["File size changes:\nImmediate or delayed write errors in a sequential zone file can cause the\nfile inode size to be inconsistent with the amount of data successfully\nwritten in the file zone. For example, the partial failure of a multi-BIO\nlarge write operation will cause the zone write pointer to advance partially,\neven though the entire write operation is reported as failed to the user.\nIn such cases, the file inode size must be advanced to reflect the zone write\npointer change and eventually allow the user to restart writing at the end of\nthe file.\nA file size may also be reduced to reflect a delayed write error detected on\nfsync(): in this case, the amount of data effectively written in the zone may\nbe less than originally indicated by the file inode size. After any such I/O\nerror, ",(0,s.jsx)(n.em,{children:"zonefs"})," always fixes the file inode size to reflect the amount of\ndata persistently stored in the file zone."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Access permission changes:\nA zone condition change to read-only is indicated with a change in the file\naccess permissions, rendering the file read-only. This disables changes to\nthe file attributes and data modification. For offline zones, all permissions\n(read and write) of the file are disabled."}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:["Further action taken by ",(0,s.jsx)(n.em,{children:"zonefs"}),' I/O error recovery can be controlled by the\nuser with the "errors=xxx" mount option. The table below summarizes the result\nof ',(0,s.jsx)(n.em,{children:"zonefs"})," I/O error processing, depending on the mount option and on the zone\nconditions."]}),"\n",(0,s.jsx)("center",{children:(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{style:{textAlign:"center"},children:'"errors=xxx" mount option'}),(0,s.jsx)(n.th,{style:{textAlign:"center"},children:"Device zone condition"}),(0,s.jsx)(n.th,{style:{textAlign:"center"},children:"File size"}),(0,s.jsx)(n.th,{style:{textAlign:"center"},children:"File read"}),(0,s.jsx)(n.th,{style:{textAlign:"center"},children:"File write"}),(0,s.jsx)(n.th,{style:{textAlign:"center"},children:"Device read"}),(0,s.jsx)(n.th,{style:{textAlign:"center"},children:"Device write"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{style:{textAlign:"center"},children:"remount-ro"}),(0,s.jsx)(n.td,{style:{textAlign:"center"},children:"good"}),(0,s.jsx)(n.td,{style:{textAlign:"center"},children:"fixed"}),(0,s.jsx)(n.td,{style:{textAlign:"center"},children:(0,s.jsx)(c,{})}),(0,s.jsx)(n.td,{style:{textAlign:"center"},children:(0,s.jsx)(h,{})}),(0,s.jsx)(n.td,{style:{textAlign:"center"},children:(0,s.jsx)(c,{})}),(0,s.jsx)(n.td,{style:{textAlign:"center"},children:(0,s.jsx)(c,{})})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{style:{textAlign:"center"},children:"remount-ro"}),(0,s.jsx)(n.td,{style:{textAlign:"center"},children:"read-only"}),(0,s.jsx)(n.td,{style:{textAlign:"center"},children:"as is"}),(0,s.jsx)(n.td,{style:{textAlign:"center"},children:(0,s.jsx)(c,{})}),(0,s.jsx)(n.td,{style:{textAlign:"center"},children:(0,s.jsx)(h,{})}),(0,s.jsx)(n.td,{style:{textAlign:"center"},children:(0,s.jsx)(c,{})}),(0,s.jsx)(n.td,{style:{textAlign:"center"},children:(0,s.jsx)(h,{})})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{style:{textAlign:"center"},children:"remount-ro"}),(0,s.jsx)(n.td,{style:{textAlign:"center"},children:"offline"}),(0,s.jsx)(n.td,{style:{textAlign:"center"},children:"0"}),(0,s.jsx)(n.td,{style:{textAlign:"center"},children:(0,s.jsx)(h,{})}),(0,s.jsx)(n.td,{style:{textAlign:"center"},children:(0,s.jsx)(h,{})}),(0,s.jsx)(n.td,{style:{textAlign:"center"},children:(0,s.jsx)(h,{})}),(0,s.jsx)(n.td,{style:{textAlign:"center"},children:(0,s.jsx)(h,{})})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{style:{textAlign:"center"},children:"zone-ro"}),(0,s.jsx)(n.td,{style:{textAlign:"center"},children:"good"}),(0,s.jsx)(n.td,{style:{textAlign:"center"},children:"fixed"}),(0,s.jsx)(n.td,{style:{textAlign:"center"},children:(0,s.jsx)(c,{})}),(0,s.jsx)(n.td,{style:{textAlign:"center"},children:(0,s.jsx)(h,{})}),(0,s.jsx)(n.td,{style:{textAlign:"center"},children:(0,s.jsx)(c,{})}),(0,s.jsx)(n.td,{style:{textAlign:"center"},children:(0,s.jsx)(c,{})})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{style:{textAlign:"center"},children:"zone-ro"}),(0,s.jsx)(n.td,{style:{textAlign:"center"},children:"read-only"}),(0,s.jsx)(n.td,{style:{textAlign:"center"},children:"as is"}),(0,s.jsx)(n.td,{style:{textAlign:"center"},children:(0,s.jsx)(c,{})}),(0,s.jsx)(n.td,{style:{textAlign:"center"},children:(0,s.jsx)(h,{})}),(0,s.jsx)(n.td,{style:{textAlign:"center"},children:(0,s.jsx)(c,{})}),(0,s.jsx)(n.td,{style:{textAlign:"center"},children:(0,s.jsx)(h,{})})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{style:{textAlign:"center"},children:"zone-ro"}),(0,s.jsx)(n.td,{style:{textAlign:"center"},children:"offline"}),(0,s.jsx)(n.td,{style:{textAlign:"center"},children:"0"}),(0,s.jsx)(n.td,{style:{textAlign:"center"},children:(0,s.jsx)(h,{})}),(0,s.jsx)(n.td,{style:{textAlign:"center"},children:(0,s.jsx)(h,{})}),(0,s.jsx)(n.td,{style:{textAlign:"center"},children:(0,s.jsx)(h,{})}),(0,s.jsx)(n.td,{style:{textAlign:"center"},children:(0,s.jsx)(h,{})})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{style:{textAlign:"center"},children:"zone-offline"}),(0,s.jsx)(n.td,{style:{textAlign:"center"},children:"good"}),(0,s.jsx)(n.td,{style:{textAlign:"center"},children:"0"}),(0,s.jsx)(n.td,{style:{textAlign:"center"},children:(0,s.jsx)(h,{})}),(0,s.jsx)(n.td,{style:{textAlign:"center"},children:(0,s.jsx)(h,{})}),(0,s.jsx)(n.td,{style:{textAlign:"center"},children:(0,s.jsx)(c,{})}),(0,s.jsx)(n.td,{style:{textAlign:"center"},children:(0,s.jsx)(c,{})})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{style:{textAlign:"center"},children:"zone-offline"}),(0,s.jsx)(n.td,{style:{textAlign:"center"},children:"read-only"}),(0,s.jsx)(n.td,{style:{textAlign:"center"},children:"0"}),(0,s.jsx)(n.td,{style:{textAlign:"center"},children:(0,s.jsx)(h,{})}),(0,s.jsx)(n.td,{style:{textAlign:"center"},children:(0,s.jsx)(h,{})}),(0,s.jsx)(n.td,{style:{textAlign:"center"},children:(0,s.jsx)(c,{})}),(0,s.jsx)(n.td,{style:{textAlign:"center"},children:(0,s.jsx)(h,{})})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{style:{textAlign:"center"},children:"zone-offline"}),(0,s.jsx)(n.td,{style:{textAlign:"center"},children:"offline"}),(0,s.jsx)(n.td,{style:{textAlign:"center"},children:"0"}),(0,s.jsx)(n.td,{style:{textAlign:"center"},children:(0,s.jsx)(h,{})}),(0,s.jsx)(n.td,{style:{textAlign:"center"},children:(0,s.jsx)(h,{})}),(0,s.jsx)(n.td,{style:{textAlign:"center"},children:(0,s.jsx)(h,{})}),(0,s.jsx)(n.td,{style:{textAlign:"center"},children:(0,s.jsx)(h,{})})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{style:{textAlign:"center"},children:"repair"}),(0,s.jsx)(n.td,{style:{textAlign:"center"},children:"good"}),(0,s.jsx)(n.td,{style:{textAlign:"center"},children:"fixed"}),(0,s.jsx)(n.td,{style:{textAlign:"center"},children:(0,s.jsx)(c,{})}),(0,s.jsx)(n.td,{style:{textAlign:"center"},children:(0,s.jsx)(c,{})}),(0,s.jsx)(n.td,{style:{textAlign:"center"},children:(0,s.jsx)(c,{})}),(0,s.jsx)(n.td,{style:{textAlign:"center"},children:(0,s.jsx)(c,{})})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{style:{textAlign:"center"},children:"repair"}),(0,s.jsx)(n.td,{style:{textAlign:"center"},children:"read-only"}),(0,s.jsx)(n.td,{style:{textAlign:"center"},children:"as is"}),(0,s.jsx)(n.td,{style:{textAlign:"center"},children:(0,s.jsx)(c,{})}),(0,s.jsx)(n.td,{style:{textAlign:"center"},children:(0,s.jsx)(h,{})}),(0,s.jsx)(n.td,{style:{textAlign:"center"},children:(0,s.jsx)(c,{})}),(0,s.jsx)(n.td,{style:{textAlign:"center"},children:(0,s.jsx)(h,{})})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{style:{textAlign:"center"},children:"repair"}),(0,s.jsx)(n.td,{style:{textAlign:"center"},children:"offline"}),(0,s.jsx)(n.td,{style:{textAlign:"center"},children:"0"}),(0,s.jsx)(n.td,{style:{textAlign:"center"},children:(0,s.jsx)(h,{})}),(0,s.jsx)(n.td,{style:{textAlign:"center"},children:(0,s.jsx)(h,{})}),(0,s.jsx)(n.td,{style:{textAlign:"center"},children:(0,s.jsx)(h,{})}),(0,s.jsx)(n.td,{style:{textAlign:"center"},children:(0,s.jsx)(h,{})})]})]})]})}),"\n",(0,s.jsx)(n.p,{children:"Further notes:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:'The "errors=remount-ro" mount option is the default behavior of zonefs I/O\nerror processing if no errors mount option is specified.'}),"\n",(0,s.jsx)(n.li,{children:'With the "errors=remount-ro" mount option, the change of file access\npermissions to "read-only" applies to all files. The file system is remounted\nread-only.'}),"\n",(0,s.jsx)(n.li,{children:"Access permission and file-size changes caused by the device transitioning\nzones to the offline condition are permanent. Remounting or reformatting the\ndevice with mkfs.zonefs (mkzonefs) will not change offline zone files back\nto a good state."}),"\n",(0,s.jsx)(n.li,{children:"All file access permission changes to read-only that are due to the device\ntransitioning zones to the read-only condition are permanent. Remounting or\nreformatting the device will not re-enable file write access."}),"\n",(0,s.jsx)(n.li,{children:'File access permission changes implied by the "remount-ro", "zone-ro" and\n"zone-offline" mount options are temporary for zones in a good condition.\nUnmounting and remounting the file system restores the previous default\n(format time values) access rights to the files affected.'}),"\n",(0,s.jsx)(n.li,{children:'The repair mount option triggers only the minimal set of I/O error recovery\nactions (that is, file size fixes for zones in a good condition). Zones\nthat are indicated as "read-only" or "offline" by the device still imply\nchanges to the zone file access permissions as noted in the table above.'}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"mount-options",children:"Mount options"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.em,{children:"zonefs"}),' defines the "errors=',(0,s.jsx)(n.em,{children:"behavior"}),'" mount option to allow the user to\nspecify zonefs behavior in response to I/O errors, inode size inconsistencies\nor zone condition changes. The defined behaviors are as follows.']}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"remount-ro (default)"}),"\n",(0,s.jsx)(n.li,{children:"zone-ro"}),"\n",(0,s.jsx)(n.li,{children:"zone-offline"}),"\n",(0,s.jsx)(n.li,{children:"repair"}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:["The run-time I/O error actions defined for each behavior are detailed in\n",(0,s.jsx)(n.a,{href:"/docs/linux/fs#io-error-handling",children:(0,s.jsx)(n.em,{children:"IO error handling"})}),". Mount-time I/O errors\ncause the mount operation to fail."]}),"\n",(0,s.jsxs)(n.p,{children:["Read-only zones are handled differently at mount time than they are at\nrun time. If a read-only zone is found at mount time, the zone is always\ntreated in the same manner as offline zones (that is, all accesses are\ndisabled and the zone file size set to 0). This is necessary, because the write\npointer of read-only zones is defined as invalid by the ZBC and ZAC standards\n(which makes it impossible to discover the amount of data that has been\nwritten to the zone). In the case of a read-only zone that is discovered at\nrun-time, as indicated in ",(0,s.jsx)(n.a,{href:"/docs/linux/fs#io-error-handling",children:(0,s.jsx)(n.em,{children:"IO error\nhandling"})}),", the size of the zone file is left\nunchanged from its last updated value."]}),"\n",(0,s.jsx)(n.h3,{id:"zonefs-user-space-tools",children:"Zonefs User Space Tools"}),"\n",(0,s.jsxs)(n.p,{children:["The ",(0,s.jsx)(n.code,{children:"mkzonefs"})," tool is used to format zoned block devices for use with ",(0,s.jsx)(n.em,{children:"zonefs"}),".\nThis tool is available on ",(0,s.jsx)("a",{href:"https://github.com/westerndigitalcorporation/zonefs-tools",target:"_blank",children:"GitHub"}),"."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.em,{children:"zonefs-tools"})," also includes a test suite that can be run against any zoned\nblock device, including\n",(0,s.jsxs)(n.a,{href:"/docs/getting-started/zbd-emulation",children:[(0,s.jsx)(n.em,{children:"nullblk"})," block device created with zoned\nmode"]}),"."]}),"\n",(0,s.jsx)(n.h3,{id:"examples",children:"Examples"}),"\n",(0,s.jsx)(n.p,{children:"The following list of commands formats a 15TB host-managed SMR HDD with 256 MB\nzones (with the conventional zones aggregation feature enabled):"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-plaintext",children:"# mkzonefs -o aggr_cnv /dev/sdX\n# mount -t zonefs /dev/sdX /mnt\n# ls -l /mnt/\ntotal 0\ndr-xr-xr-x 2 root root     1 Nov 25 13:23 cnv\ndr-xr-xr-x 2 root root 55356 Nov 25 13:23 seq\n"})}),"\n",(0,s.jsx)(n.p,{children:"The size of the zone files' sub-directories indicates the number of files\nthat exist for each type of zone. In this example, there is only one\nconventional zone file (all conventional zones are aggregated under a single\nfile):"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-plaintext",children:"# ls -l /mnt/cnv\ntotal 137101312\n-rw-r----- 1 root root 140391743488 Nov 25 13:23 0\n"})}),"\n",(0,s.jsx)(n.p,{children:"This aggregated conventional zone file can be used as a regular file:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-plaintext",children:"# mkfs.ext4 /mnt/cnv/0\n# mount -o loop /mnt/cnv/0 /data\n"})}),"\n",(0,s.jsx)(n.p,{children:'The "seq" sub-directory, which groups files for sequential write zones, has\n55356 zones in this example:'}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-plaintext",children:"# ls -lv /mnt/seq\ntotal 14511243264\n-rw-r----- 1 root root 0 Nov 25 13:23 0\n-rw-r----- 1 root root 0 Nov 25 13:23 1\n-rw-r----- 1 root root 0 Nov 25 13:23 2\n...\n-rw-r----- 1 root root 0 Nov 25 13:23 55354\n-rw-r----- 1 root root 0 Nov 25 13:23 55355\n"})}),"\n",(0,s.jsx)(n.p,{children:"For sequential write zone files, the file size changes as data is appended at\nthe end of the file. This is similar to the behavior of any regular file\nsystem:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-plaintext",children:"# dd if=/dev/zero of=/mnt/seq/0 bs=4096 count=1 conv=notrunc oflag=direct\n1+0 records in\n1+0 records out\n4096 bytes (4.1 kB, 4.0 KiB) copied, 0.00044121 s, 9.3 MB/s\n\n# ls -l /mnt/seq/0\n-rw-r----- 1 root root 4096 Nov 25 13:23 /mnt/seq/0\n"})}),"\n",(0,s.jsx)(n.p,{children:"The written file can be truncated to the zone size, which prevents any further\nwrite operations:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-plaintext",children:"# truncate -s 268435456 /mnt/seq/0\n# ls -l /mnt/seq/0\n-rw-r----- 1 root root 268435456 Nov 25 13:49 /mnt/seq/0\n"})}),"\n",(0,s.jsx)(n.p,{children:"Truncation to 0 size allows freeing the file zone storage space and restarts\nappend-writes to the file:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-plaintext",children:"# truncate -s 0 /mnt/seq/0\n# ls -l /mnt/seq/0\n-rw-r----- 1 root root 0 Nov 25 13:49 /mnt/seq/0\n"})}),"\n",(0,s.jsx)(n.p,{children:"Since files are statically mapped to zones on the disk, the number of blocks of\na file as reported by stat() and fstat() indicates the size of the file zone:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-plaintext",children:"# stat /mnt/seq/0\nFile: /mnt/seq/0\nSize: 0         \tBlocks: 524288     IO Block: 4096   regular empty file\nDevice: 870h/2160d\tInode: 50431       Links: 1\nAccess: (0640/-rw-r-----)  Uid: (    0/    root)   Gid: (    0/    root)\nAccess: 2019-11-25 13:23:57.048971997 +0900\nModify: 2019-11-25 13:52:25.553805765 +0900\nChange: 2019-11-25 13:52:25.553805765 +0900\nBirth: -\n"})}),"\n",(0,s.jsx)(n.p,{children:'The number of blocks of the file ("Blocks") in units of 512B blocks gives the\nmaximum file size of 524288 * 512 B = 256 MB, which corresponds to the device\nzone size in this example. Note that the "IO block" field always indicates the\nminimum I/O size for writes and that it corresponds to the device\'s physical\nsector size.'}),"\n",(0,s.jsx)(n.h2,{id:"f2fs",children:"f2fs"}),"\n",(0,s.jsxs)(n.p,{children:["The ",(0,s.jsx)(n.em,{children:"Flash-Friendly File System"})," (",(0,s.jsx)(n.em,{children:"f2fs"}),') was designed on the basis of a\nlog-structured file system approach, but was modified to avoid the classical\nproblems of the traditional log-structured approach (e.g. the snowball effect\nof "wandering trees" and the high "cleaning overhead").']}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.em,{children:"f2fs"})," supports various parameters not only for configuring on-disk layout but\nalso for selecting allocation and cleaning algorithms."]}),"\n",(0,s.jsx)(n.h3,{id:"zoned-block-device-support",children:"Zoned Block Device Support"}),"\n",(0,s.jsxs)(n.p,{children:["Zoned block device support was added to ",(0,s.jsx)(n.em,{children:"f2fs"})," with kernel 4.10. Because ",(0,s.jsx)(n.em,{children:"f2fs"}),"\nuses a metadata-block on-disk format with fixed-block location, only zoned\nblock devices that include conventional zones are supported. Zoned devices\ncomposed entirely of sequential zones cannot be used with ",(0,s.jsx)(n.em,{children:"f2fs"})," as a\nstandalone device and they require a multi-device setup in order to place\nmetadata blocks on randomly writable storage. ",(0,s.jsx)(n.em,{children:"f2fs"})," supports multi-device\nsetup where multiple block device address spaces are linearly concatenated to\nform a logically larger block device. The ",(0,s.jsx)(n.a,{href:"/docs/linux/dm#dm-linear",children:(0,s.jsx)(n.em,{children:"dm-linear"})}),"\ndevice mapper target can also be used to create a logical device that is\ncomposed of both conventional zones and sequential zones suitable for ",(0,s.jsx)(n.em,{children:"f2fs"}),"."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.em,{children:"f2fs"})," zoned block device support was achieved using the following principles."]}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Section Alignment"})," In ",(0,s.jsx)(n.em,{children:"f2fs"}),", a section is a group of fixed-size\nsegments (2 MB). The number of segments in a section is determined to match\nthe zoned device zone size. For example: with a 256 MB zone size, a section\ncontains 128 segments of 2MB."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Forced LFS mode"})," By default, ",(0,s.jsx)(n.em,{children:"f2fs"})," tries to optimize block allocation\n(in order to avoid excessive append write) by allowing some random writes\nwithin segments. The LFS mode forces sequential writes to segments and\nforces the sequential use of segments within sections, which results in\nfull compliance with the zoned block device's write constraint."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Zone reset as discard operation"})," In the past, block ",(0,s.jsx)(n.em,{children:"discard"})," (or ",(0,s.jsx)(n.em,{children:"trim"}),')\nindicated to a device that a block or range of blocks are no longer in use.\nThis has been replaced with the execution of a "zone write pointer reset"\ncommand when all blocks of all segments of a section are free. This allows\nthe section to be reused.']}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:["Compared to a solution that uses the ",(0,s.jsx)(n.em,{children:"dm-zoned"})," device mapper target,\nthe performance of ",(0,s.jsx)(n.em,{children:"f2fs"}),' on zoned devices does not suffer from "zone reclaim\noverhead", because writes are always sequential and do not require on-disk\ntemporary buffering. ',(0,s.jsx)(n.em,{children:"f2fs"})," garbage collection (segment cleanup) generates\noverhead only for workloads that frequently delete files or modify files' data."]}),"\n",(0,s.jsx)(n.h3,{id:"zone-capacity-support",children:"Zone Capacity Support"}),"\n",(0,s.jsxs)(n.p,{children:["NVMe ZNS SSDs can have a per ",(0,s.jsx)(n.a,{href:"/docs/introduction/zns#zone-capacity-and-zone-size",children:"zone capacity that is smaller than the zone\nsize"}),". To support ZNS\ndevices, ",(0,s.jsx)(n.em,{children:"f2fs"})," ensures that block allocation and accounting considers only the\nblocks in a zone that are within the zone's capacity. This support for NVMe ZNS\nzone capacity has been available since it was introduced in Linux kernel version\n5.10."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.em,{children:"f2fs"})," volumes need some storage space that is randomly writable in order\nto store and update in-place metadata blocks for the volume. Since NVMe zoned\nnamespaces do not have conventional zones, a ",(0,s.jsx)(n.em,{children:"f2fs"})," volume cannot be\nself-contained within a single NVMe zoned namespace. To format an ",(0,s.jsx)(n.em,{children:"f2fs"})," volume\nusing a NVMe zoned namespace, a multi-device volume format must be used in order\nto provide an additional regular block device to store the volume metadata\nblocks. This additional regular block device can be either a regular namespace\non the same NVMe device or a regular namespace on another NVMe device."]}),"\n",(0,s.jsx)(n.h3,{id:"limitations",children:"Limitations"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.em,{children:"f2fs"})," uses 32-bit block numbers with a block size of 4 KB. This results in a\nmaximum volume size of 16 TB. Any device or combination of devices (for a\nmulti-device volume) with a total capacity that is larger than 16 TB cannot\nbe used with ",(0,s.jsx)(n.em,{children:"f2fs"}),"."]}),"\n",(0,s.jsxs)(n.p,{children:["To overcome this limit, the ",(0,s.jsx)(n.a,{href:"/docs/linux/dm#dm-linear",children:(0,s.jsx)(n.em,{children:"dm-linear"})})," device\nmapper target can be used to partition a zoned block device into serviceable,\nsmaller logical devices. This configuration must ensure that each logical device\nthat is created is assigned a sufficient amount of conventional zones to store\n",(0,s.jsx)(n.em,{children:"f2fs"})," fixed location metadata blocks."]}),"\n",(0,s.jsx)(n.h3,{id:"usage-example-with-a-host-managed-smr-hdd",children:"Usage Example with a Host Managed SMR HDD"}),"\n",(0,s.jsxs)(n.p,{children:["To format a zoned block device with ",(0,s.jsx)(n.em,{children:"mkfs.f2fs"}),", the option ",(0,s.jsx)(n.code,{children:"-m"})," must be\nspecified:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-plaintext",children:'# mkfs.f2fs -m /dev/sdb\n\n\tf2fs-tools: mkfs.f2fs Ver: 1.12.0 (2018-11-12)\n\nInfo: Disable heap-based policy\nInfo: Debug level = 0\nInfo: Trim is enabled\nInfo: [/dev/sdb] Disk Model: HGST HSH721415AL\nInfo: Host-managed zoned block device:\n      55880 zones, 524 randomly writeable zones\n      65536 blocks per zone\nInfo: Segments per section = 128\nInfo: Sections per zone = 1\nInfo: sector size = 4096\nInfo: total sectors = 3662151680 (14305280 MB)\nInfo: zone aligned segment0 blkaddr: 65536\nInfo: format version with\n  "Linux version 5.0.16-300.fc30.x86_64 (mockbuild@bkernel03.phx2.fedoraproject.org) (gcc version 9.1.1 20190503 (Red Hat 9.1.1-1) (GCC)) #1 SMP Tue May 14 19:33:09 UTC 2019"\nInfo: [/dev/sdb] Discarding device\nInfo: Discarded 14305280 MB\nInfo: Overprovision ratio = 0.600%\nInfo: Overprovision segments = 86254 (GC reserved = 43690)\nInfo: format successful\n'})}),"\n",(0,s.jsx)(n.p,{children:"The formatted zoned block device can now be directly mounted. No further\nsetup is necessary:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-plaintext",children:"# mount /dev/sdb /mnt\n"})}),"\n",(0,s.jsx)(n.h3,{id:"usage-example-with-a-nvme-zns-ssd",children:"Usage Example with a NVMe ZNS SSD"}),"\n",(0,s.jsxs)(n.p,{children:["Unlike SMR hard-disks, the kernel by default does not select the ",(0,s.jsx)(n.em,{children:"mq-deadline"}),"\nblock-IO scheduler for block devices that represent NVMe zoned namespaces. To\nensure that the regular write operations used by ",(0,s.jsx)(n.em,{children:"f2fs"})," are delivered to the\ndevice in sequential order, the IO scheduler for the NVMe zoned namespace block\ndevice must be set to ",(0,s.jsx)(n.em,{children:"mq-deadline"}),". This is done with the following command:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-plaintext",children:"# echo mq-deadline > /sys/block/nvme1n1/queue/scheduler\n"})}),"\n",(0,s.jsxs)(n.p,{children:["In the above command, ",(0,s.jsx)(n.code,{children:"/dev/nvme1n1"})," is the block device file of the zoned\nnamespace that will be used for the ",(0,s.jsx)(n.em,{children:"f2fs"})," volume. Using this namespace, a\nmulti-device ",(0,s.jsx)(n.em,{children:"f2fs"})," volume that uses an additional regular block device\n(",(0,s.jsx)(n.code,{children:"/dev/nvme0n1"})," in the following example) can be formatted using the ",(0,s.jsx)(n.em,{children:"-c"}),"\noption of ",(0,s.jsx)(n.em,{children:"mkfs.f2fs"}),", as shown in the following example:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-plaintext",children:"# mkfs.f2fs -f -m -c /dev/nvme1n1 /dev/nvme0n1\n\n        F2FS-tools: mkfs.f2fs Ver: 1.14.0 (2021-06-23)\n\nInfo: Disable heap-based policy\nInfo: Debug level = 0\nInfo: Trim is enabled\nInfo: Host-managed zoned block device:\n      2048 zones, 0 randomly writeable zones\n      524288 blocks per zone\nInfo: Segments per section = 1024\nInfo: Sections per zone = 1\nInfo: sector size = 4096\nInfo: total sectors = 1107296256 (4325376 MB)\nInfo: zone aligned segment0 blkaddr: 524288\nInfo: format version with\n  \"Linux version 5.13.0-rc6+ (user1@brahmaputra) (gcc (Ubuntu 10.3.0-1ubuntu1) 10.3.0, GNU ld (GNU Binutils for Ubuntu) 2.36.1) #2 SMP Fri Jun 18 16:45:29 IST 2021\"\nInfo: [/dev/nvme0n1] Discarding device\nInfo: This device doesn't support BLKSECDISCARD\nInfo: This device doesn't support BLKDISCARD\nInfo: [/dev/nvme1n1] Discarding device\nInfo: Discarded 4194304 MB\nInfo: Overprovision ratio = 3.090%\nInfo: Overprovision segments = 74918 (GC reserved = 40216)\nInfo: format successful\n"})}),"\n",(0,s.jsx)(n.p,{children:"To mount the volume formatted with the above command, the regular block device\nmust be specified:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-plaintext",children:"# mount -t f2fs /dev/nvme0n1 /mnt/f2fs/\n"})}),"\n",(0,s.jsx)(n.h2,{id:"btrfs",children:"Btrfs"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.em,{children:"Btrfs"})," is a file system based on the copy-on-write (CoW) principle. This\nprinciple has the result that no block update can be written in-place.\n",(0,s.jsx)(n.em,{children:"Btrfs"})," currently supports zoned block devices, but that support is\nexperimental."]}),"\n",(0,s.jsx)(n.h3,{id:"zoned-block-device-support-1",children:"Zoned Block Device Support"}),"\n",(0,s.jsxs)(n.p,{children:["Zoned block device support was added to ",(0,s.jsx)(n.em,{children:"btrfs"})," with kernel 5.12. Because\nsuper-blocks are the only on-disk data structure with a fixed location in\n",(0,s.jsx)(n.em,{children:"btrfs"}),", zoned block device support introduces the concept of log-structured\nsuper-blocks to eliminate in-place updates (overwrites) of fixed super block\nlocations. Zoned mode reserves two consecutive zones to hold each of the\nsuper-blocks (primary and backup super-blocks) in ",(0,s.jsx)(n.em,{children:"btrfs"}),". When a new\nsuper-block is written, it is appended to its respective super-block zone.\nAfter the first super-block zone is filled, the next super block is written to\nthe second super-block zone and the first is reset. At mount time, ",(0,s.jsx)(n.em,{children:"btrfs"}),"\ncan find the latest version of the super-block by looking at the position of\nthe zone write pointer of the super-block zones. The most recent and valid\nsuper-block is always the last  block stored before the write pointer\nposition."]}),"\n",(0,s.jsx)(n.h3,{id:"block-allocation-changes",children:"Block Allocation Changes"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.em,{children:"Btrfs"})," block management relies on grouping blocks into ",(0,s.jsx)(n.em,{children:"block groups"}),".\nEach ",(0,s.jsx)(n.em,{children:"block group"})," is composed of one or more ",(0,s.jsx)(n.em,{children:"device extents"}),". The device\nextents of a block group may belong to different devices (e.g. in the case\nof a RAID volume). ZBD support changes the size of a device extent from its\ndefault size to the size of the device zones. This ensures that all device\nextents are always aligned to a zone."]}),"\n",(0,s.jsx)(n.p,{children:"Allocation of blocks within a block group is changed so that the allocation is\nalways sequential from the beginning of the block group. To do this, an\nallocation pointer is added to block groups and used as the allocation hint.\nThese changes ensure that blocks freed below the allocation pointer are\nignored, which results in sequential block allocation within each group\nregardless of the block group usage."}),"\n",(0,s.jsx)(n.h3,{id:"io-management",children:"I/O Management"}),"\n",(0,s.jsx)(n.p,{children:'Although the introduction of the allocation pointer ensures that blocks are\nallocated sequentially within groups (and therefore sequentially within zones),\nI/O operations that write out newly allocated blocks can be issued out of\norder, and this can cause errors when writing to sequential zones. This problem\nis solved by introducing a "write I/O request staging list" to each block group.\nThis list is used to delay the execution of unaligned write requests within a\ngiven block group.'}),"\n",(0,s.jsx)(n.p,{children:"The zones of a block group are reset to allow rewriting only when the block\ngroup is free (that is, when all the blocks within the block group are\nunused)."}),"\n",(0,s.jsxs)(n.p,{children:["When dealing with ",(0,s.jsx)(n.em,{children:"btrfs"})," volumes that are composed of multiple disks,\nrestrictions are added to ensure that all the disks have the same zone model\n(and in the case of zoned block devices, the same zone size). This matches the\nexisting ",(0,s.jsx)(n.em,{children:"btrfs"})," constraint that dictates that all device extents in a block\ngroup must have the same size."]}),"\n",(0,s.jsxs)(n.p,{children:["All writes to data block groups use ",(0,s.jsx)(n.a,{href:"/docs/introduction/zns#zone-append",children:"Zone Append\nwriting"}),", which makes it possible to maintain\na high queue depth without violating the device zone's sequential write\nconstraints. Every write to dedicated meta-data block groups is serialized\nwith a file-system-global zoned metadata I/O lock."]}),"\n",(0,s.jsx)(n.h3,{id:"zone-capacity-support-1",children:"Zone Capacity Support"}),"\n",(0,s.jsxs)(n.p,{children:["NVMe ZNS SSDs can have a per ",(0,s.jsx)(n.a,{href:"/docs/introduction/zns#zone-capacity-and-zone-size",children:"zone capacity that is smaller than the zone\nsize"}),".  To support ZNS\ndevices, ",(0,s.jsx)(n.em,{children:"btrfs"})," ensures that block allocation and accounting considers only\nthe blocks in a zone that are within the zone capacity. This support for NVMe\nZNS zone capacity has been available since Linux kernel version 5.16. Also,\nsince kernel 5.16, ",(0,s.jsx)(n.em,{children:"btrfs"}),' keeps track of the number of active zones on\na device and issues "Zone Finish" commands as needed.']}),"\n",(0,s.jsx)(n.h3,{id:"limitations-1",children:"Limitations"}),"\n",(0,s.jsxs)(n.p,{children:["Not all features currently available in ",(0,s.jsx)(n.em,{children:"btrfs"})," are supported in the current\nzoned mode of the file-system."]}),"\n",(0,s.jsx)(n.p,{children:"These unavailable features include:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"RAID Support"}),"\n",(0,s.jsx)(n.li,{children:"NOCOW Support"}),"\n",(0,s.jsx)(n.li,{children:"Support for fallocate(2)"}),"\n",(0,s.jsx)(n.li,{children:"Mixed data and meta-data block groups"}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"system-requirements",children:"System Requirements"}),"\n",(0,s.jsxs)(n.p,{children:["In order to use ",(0,s.jsx)(n.em,{children:"btrfs"})," on zoned block devices, the following minimum system\nrequirements must be met:"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Linux kernel 5.12 (for SMR) or 5.16 (for NVMe ZNS)"}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.em,{children:"btrfs-progs"})," 5.12 (for SMR) or 5.15 (for NVMe ZNS)"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.em,{children:"util-linux"})," 2.38"]}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:["The source code for ",(0,s.jsx)(n.em,{children:"btrfs-progs"})," ",(0,s.jsx)("a",{href:"https://github.com/kdave/btrfs-progs",target:"_blank",children:"is hosted on GitHub"}),". More information on ",(0,s.jsx)(n.em,{children:"util-linux"})," can be\nfound ",(0,s.jsx)(n.a,{href:"/docs/tools/util-linux",children:"here"}),"."]}),"\n",(0,s.jsxs)(n.p,{children:["If a kernel supports ",(0,s.jsx)(n.em,{children:"btrfs"})," on a zoned block device, it will automatically\nselect the ",(0,s.jsx)(n.em,{children:"mq_deadline"})," block IO scheduler by default. This ensures ",(0,s.jsx)(n.a,{href:"/docs/linux/sched",children:"write\nordering correctness"})," for any SMR hard-disk that is used in a\nzoned ",(0,s.jsx)(n.em,{children:"btrfs"})," volume."]}),"\n",(0,s.jsxs)(n.p,{children:["As in the case of ",(0,s.jsxs)(n.a,{href:"/docs/linux/fs#usage-example-with-a-nvme-zns-ssd",children:[(0,s.jsx)(n.em,{children:"f2fs"})," use with an NVMe ZNS\nSSD"]}),", the ",(0,s.jsx)(n.em,{children:"mq-deadline"}),"\nscheduler must be set manually to ensure that the regular write operations used\nby ",(0,s.jsx)(n.em,{children:"btrfs"})," are delivered to the device in sequential order. For a NVMe zoned\nnamespace device ",(0,s.jsx)(n.em,{children:"/dev/nvmeXnY"}),", this is done with the following command:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-plaintext",children:"# echo mq-deadline > /sys/block/nvmeXnY/queue/scheduler\n"})}),"\n",(0,s.jsxs)(n.p,{children:["Alternatively, the following udev rule can be used to automatically set the\n",(0,s.jsx)(n.em,{children:"mq-deadline"})," scheduler for all zoned block devices that have been formatted\nwith btrfs."]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-plain",metastring:"text",children:'SUBSYSTEM!="block", GOTO="btrfs_end"\nACTION!="add|change", GOTO="btrfs_end"\nENV{ID_FS_TYPE}!="btrfs", GOTO="btrfs_end"\n\nATTR{queue/zoned}=="host-managed", ATTR{queue/scheduler}="mq-deadline"\n\nLABEL="btrfs_end"\n'})}),"\n",(0,s.jsx)(n.h3,{id:"usage-example-with-a-host-managed-smr-hdd-1",children:"Usage example with a Host Managed SMR HDD"}),"\n",(0,s.jsxs)(n.p,{children:["To format a zoned block device with ",(0,s.jsx)(n.em,{children:"mkfs.btrfs"}),", the ",(0,s.jsx)(n.code,{children:"-m single"})," and ",(0,s.jsx)(n.code,{children:"-d single"}),' options must be specified, because no block group profile other\nthan "single" is currently supported.']}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-plaintext",children:"# mkfs.btrfs -m single -d single /dev/sda\nbtrfs-progs v5.15.1\nSee http://btrfs.wiki.kernel.org for more information.\n\nZoned: /dev/sda: host-managed device detected, setting zoned feature\nResetting device zones /dev/sda (74508 zones) ...\nNOTE: several default settings have changed in version 5.15, please make sure\n      this does not affect your deployments:\n      - DUP for metadata (-m dup)\n      - enabled no-holes (-O no-holes)\n      - enabled free-space-tree (-R free-space-tree)\n\nLabel:              (null)\nUUID:               7ffa00fe-c6a3-4c6c-890f-858e17118c66\nNode size:          16384\nSector size:        4096\nFilesystem size:    18.19TiB\nBlock group profiles:\n  Data:             single          256.00MiB\n  Metadata:         single          256.00MiB\n  System:           single          256.00MiB\nSSD detected:       no\nZoned device:       yes\n  Zone size:        256.00MiB\nIncompat features:  extref, skinny-metadata, no-holes, zoned\nRuntime features:   free-space-tree\nChecksum:           crc32c\nNumber of devices:  1\nDevices:\n   ID        SIZE  PATH\n    1    18.19TiB  /dev/sda\n"})}),"\n",(0,s.jsx)(n.p,{children:"The formatted block device can now be directly mounted. No other setup is\nnecessary."}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-plaintext",children:"# mount /dev/sda /mnt\n"})}),"\n",(0,s.jsx)(n.h2,{id:"xfs",children:"XFS"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.em,{children:"XFS"})," currently does not support zoned block devices. The\n",(0,s.jsx)(n.a,{href:"/docs/linux/dm#dm-zoned",children:(0,s.jsx)(n.em,{children:"dm-zoned"})})," device mapper target must be used to\nenable zoned device use with ",(0,s.jsx)(n.em,{children:"XFS"}),"."]}),"\n",(0,s.jsxs)(n.p,{children:["An early ",(0,s.jsx)("a",{href:"http://xfs.org/images/f/f6/Xfs-smr-structure-0.2.pdf",target:"_blank",children:" design document"})," discussed the development work necessary\nto support host aware and host managed disks with ",(0,s.jsx)(n.em,{children:"XFS"}),'. Parts of this design\nhave already been implemented and included into the kernel stable releases\n(e.g. the "per inode reverse block mapping b-trees" feature). However, more\nwork is necessary to fully support zoned block devices.']}),"\n",(0,s.jsx)(n.h2,{id:"ext4",children:"ext4"}),"\n",(0,s.jsxs)(n.p,{children:["Attempts at improving ",(0,s.jsx)(n.em,{children:"ext4"})," performance with host aware zoned block devices by\nmaking changes to the file system journal management are described in in ",(0,s.jsx)("a",{href:"https://lwn.net/Articles/720226/",target:"_blank",children:"this article"}),". These\nchanges are small and succeed in maintaining good performance. However, support\nfor host managed zoned block devices is not provided, because some of the\nfundamental aspects of ",(0,s.jsx)(n.em,{children:"ext4"})," design cannot easily be changed to match host\nmanaged device constraints."]}),"\n",(0,s.jsxs)(n.p,{children:["The field of host optimizations for host aware zoned block devices remains in\nthe research phase and is not included in ",(0,s.jsx)(n.em,{children:"ext4"})," stable kernel releases. It\nshould also be noted that ",(0,s.jsx)(n.em,{children:"ext4"})," does not support host managed disks. As with\n",(0,s.jsx)(n.em,{children:"XFS"}),", however, the ",(0,s.jsx)(n.em,{children:"ext4"})," file system can be used together with the\n",(0,s.jsx)(n.a,{href:"/docs/linux/dm#dm-zoned",children:(0,s.jsx)(n.em,{children:"dm-zoned"})})," device mapper target."]})]})}function u(e={}){const{wrapper:n}={...(0,i.a)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(f,{...e})}):f(e)}},1151:(e,n,t)=>{t.d(n,{Z:()=>l,a:()=>r});var s=t(7294);const i={},o=s.createContext(i);function r(e){const n=s.useContext(o);return s.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:r(e.components),s.createElement(o.Provider,{value:n},e.children)}}}]);